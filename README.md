# SenseBridge: Enhancing Hybrid Communication Through Motion-Aware Interaction
**Author:** Chia Hui Yen | 
**Coordinator:** Graham | 
**Mentor:** Prof. Vernelle A. A. Noel, Ph.D. | 
**Teaching Assistant:** Stella Shen

# About the proejct
SenseBridge is an innovative system that bridges the gap between virtual and physical communication by leveraging non-verbal cues and body motion data. The project explores how motion capture technology can create more authentic and immersive hybrid communication experiences.  
  
![image](https://github.com/user-attachments/assets/27945a0f-4b43-44f2-8190-538e7c34dd69)

![image](https://github.com/user-attachments/assets/3e3fd48e-b478-4eaf-abc6-3c831c3944a6)

## Features

### 1. 3D Messenger & Virtual Sticky Notes
- Create and share virtual messages through air-drawn patterns
- Location and pose-based message delivery
- Kinect sensor integration for precise gesture tracking
- Contextual message triggers based on recipient's position

### 2. Sensing Status System
- Passive emotional state monitoring through motion analysis
- Machine learning-powered behavior classification
- Real-time mood and physical state inference
- Privacy-conscious ambient awareness for remote connections

### 3. Video Call Enhancer
- Dynamic background music adjustment based on speech detection
- Gesture-controlled camera zoom functionality
- Enhanced engagement through motion-aware interactions
- Seamless integration with existing video call platforms

## Theoretical Framework  
The project is built on several key theoretical foundations:
- **Virtualization as a Creative Force** (Lévy): Transcending spatial and temporal constraints
- **Ubiquitous Computing** (Mark Weiser): Seamless integration of physical and virtual interactions
- **Information Design** (Simone C. Niquille): Careful curation of meaningful data
- **Medium Theory** (McLuhan): Body motion as a transformative communication medium

## Demo

Check out our interactive demo:
[SenseBridge Demo](https://www.figma.com/slides/ZhPBfGoOq9w9AAIFrECFcy/SenseBridge-Demo?node-id=0-1&t=BSxCTmvbE4Hw7iX7-1)

## Project Structure
```
.
├── main.py
├── sendMessage.py
└── Skeleton Constructor_Kinect-0212-final.gh
```

## Impact & Applications
This is an experimental protopye to demonstrates how technology can humanize virtual-physical world interactions by using motion data as a subtle input to enhance communication and engagement.
SenseBridge has potential applications in:
- Remote work environments
- Long-distance relationships
- Virtual social gatherings
- Educational settings
- Emotions communication

## Future Development

We continue to explore ways to:
- Expand motion detection capabilities
- Enhance privacy features
- Improve machine learning models
- Integrate with more platforms
- Develop additional interaction patterns

## Reference
1. Sarver, D. E., Rapport, M. D., Kofler, M. J., et al. (2015). Journal of Abnormal Child Psychology, 43(8), 1219–1232
2. Lévy, P. (1998). Becoming virtual: Reality in the digital age. Plenum Trade.
3. McLuhan, M. (1964). Understanding media: The extensions of man. McGraw-Hill.
4. Too much information. (n.d.). e-flux. Retrieved from https://www.e-flux.com/architecture/intelligence/310403/
5. Weiser, M. (1991). The computer for the 21st century. Scientific American, 265(3), 94–104.
6. Kelliher, A. (n.d.). Critical multimedia. Carnegie Mellon University.
